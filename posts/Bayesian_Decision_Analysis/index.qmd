---
title: "Bayesian Decision Analysis in PyMC"
description: Your act was unwise, I exclaimed as you see by the outcome. He solemnly eyed me. <br />
 When choosing the course of my action, said he, <br />
 I had not the outcome to guide me. - Ambrose Bierce
date: "8/20/2022"
categories: [Bayesian Statistics ,PyMC]
image: ""
draft: True
execute: 
  eval: false
# highlight-style: arrow
---

While oftentimes Statistical Analysis stops with the hopefully successfull inference of unknown parameters of interests. , one is often interested not only in the inference of unknown parameters, but also which results these parameters imply to actions in the real world. One can see the use of a custom loss function as a way to rebalance the associated consequences. Certain outcomes can have a profound implication in the real world and the loss function gives us a way to quantify this. For example, could a misjudgement end up in financial ruin or death, or both. The decision end up being conservative even tough the posterior probabilities assign a high value to the outcome.

Note that the utility function is just based on a judgement which is purely subjective. It is also not constrained to follow the principle of maximum entropy which ensures us in the choice of prior that we impose no information which we not have.



```{python}
import arviz as az
import numpy as np
import pymc as pm
```

### 1. Space of possible Decisions and outcomes

We start by defining our set of decisions which our individual can make and the outcomes which resulted from every decision.
In our case we deal with a decision of a transport mode and an associated time and cost. 

```{python}
modes = ["walk", "bike", "public", "cab"]
```


### 2. Probability distribution of outcomes conditional on decisions

Every decision $d \in D$ yields an outcome $x=(c, t) \in X$. The density we need looks like the following:
$$
p(x|d, x^{obs}, d^{obs})= \int p(x|d,\theta) \cdot p(\theta|x^{obs}, d^{obs})d\theta
$$

The commute time $t_n$ aswell as the cost $c_n$ are modeled as follows:

\begin{align*}

t_n &\sim lognormal(\mu_{d[n]}, \sigma_{d[n]})\\
\mu_k &\sim normal(0,1) \\
\sigma_k &\sim lognormal(0, 0.25) \\

c_n &\sim lognormal(\nu_{d[n]}, \tau_{d[n]}) \\
\nu_k &\sim normal(0,1) \\
\tau_k &\sim lognormal(0,0.25)
\end{align*}


### 3. Defining our utility function

The utility function $U(X)$ takes an outcome and maps it to a real number which is our resulting utility. Our utility is a linear function of the cost and the time.

```{python}
def utility(cost, time):
    return -(cost+5*time)
```




### 4. Compute the expected utility

```{python}
with pm.Model(coords={"modes": modes}) as discrete_choice_model:

    #Priors for time
    mu = pm.Normal("mu", 0, 1)
    sigma = pm.LogNormal("sigma", 0, 0.25)

    time = pm.LogNormal("time", mu, sigma, dims="modes")

    #Priors for cost
    nu = pm.Normal("nu", 0, 1)
    tau = pm.LogNormal("tau", 0, 0.25)

    cost = pm.LogNormal("cost", nu, tau, dims="modes")

    #utility 
    util = pm.Deterministic("utility", utility(cost, time), dims="modes")
```




```{python}
with discrete_choice_model:
    idata = pm.sample(1000, tune=2500, random_seed=RANDOM_SEED, target_accept=0.95)
```




```{python}
with discrete_choice_model:
    pp = pm.sample_posterior_predictive(idata, random_seed=RANDOM_SEED)
```



```{python}
az.summary(idata, filter_vars="like", var_names="utility")["mean"].idxmax()
```


The uncertainty in the expected utility gets propagated trough the uncertainty in the prediction, which itself gets propagated trough the uncertainty in our decision variables.